{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame as df\n",
    "import re\n",
    "from tqdm import tqdm_notebook\n",
    "from tqdm.notebook import tqdm\n",
    "import operator\n",
    "from konlpy.tag import Okt\n",
    "Okt = Okt()\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager, rc\n",
    "font_path = \"C:/Windows/Fonts/NGULIM.TTF\"\n",
    "font = font_manager.FontProperties(fname=font_path).get_name()\n",
    "rc('font', family=font)\n",
    "from math import log\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('wanted_crawling.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checking_null(data):\n",
    "    print(data.isnull().sum())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#불필요 행 제거 및 데이터 양 확인\n",
    "def del_null(data):\n",
    "    print('기존 데이터 개수는 ',len(data))\n",
    "        \n",
    "    data=data.drop_duplicates()\n",
    "    print('중복제거 데이터 개수는 ',len(data))\n",
    "        \n",
    "    data=data.dropna(subset=['직무','유사직무'])\n",
    "    data = data.reset_index(drop=True)\n",
    "    print('직무,유사직무 결측값제거 데이터 개수',len(data))\n",
    "    \n",
    "    \n",
    "    ## 이상한 에러값(길이10이하, \\n만 있는 애들) 공백으로 만들기\n",
    "    for i in tqdm_notebook(range(len(data))):\n",
    "        if len(str(data['주요업무'][i])) < 10 and '\\\\n' in str(data['주요업무'][i]):       \n",
    "            data.loc[i,['주요업무']] = ''\n",
    "        if len(str(data['자격요건'][i])) < 10 and '\\\\n' in str(data['자격요건'][i]):\n",
    "            data.loc[i,['자격요건']] = ''\n",
    "        if len(str(data['우대사항'][i])) < 10 and '\\\\n' in str(data['우대사항'][i]):\n",
    "            data.loc[i,['우대사항']] = ''\n",
    "    data = data.reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    ## '주요업무', '자격요건', '우대사항' 전부 글자수 10미만인거 제거\n",
    "    idx = []\n",
    "    for i in tqdm_notebook(range(len(data))):\n",
    "        if len(str(data['주요업무'][i])) < 10 and len(str(data['자격요건'][i])) < 10 and len(str(data['우대사항'][i])) < 10:\n",
    "            idx.append(i)\n",
    "    data = data.drop(idx)\n",
    "    data = data.reset_index(drop=True)\n",
    "    print('완료된 데이터 개수',len(data))\n",
    "    return data\n",
    "    \n",
    "    \n",
    "\n",
    "       \n",
    "## 중국어,일본어 10개이상 포함된 애들 빼기    \n",
    "def del_chinese_japanese(data):\n",
    "    index=[]\n",
    "    for i in range(len(data)):\n",
    "        temp = str(data['주요업무'][i]) + str(data['자격요건'][i]) + str(data['우대사항'][i])\n",
    "        x=re.findall(r'[\\u4e00-\\u9fff]+', temp)\n",
    "        y=re.findall(r'[\\u3040-\\u30FC]+', temp)\n",
    "        if len(list(set(x)))>10 or len(list(set(y)))>10:\n",
    "            index.append(i)\n",
    "\n",
    "    data = data.drop(index)\n",
    "    data = data.reset_index(drop=True)\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 리스트 원소들 앞뒤 여백제거 함수\n",
    "def strip_(list):\n",
    "    temp=[]\n",
    "    for j in list:\n",
    "        if len(str(j)) > 1:\n",
    "            temp.append(j.strip())\n",
    "    return temp\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 데이터 내 원소들 \\t와 • 제거, 앞뒤 여백 제거\n",
    "def del_error(data):\n",
    "    for i in tqdm(range(len(data))):\n",
    "        try:\n",
    "            data.loc[i,'주요업무']='\\\\n'.join(strip_(data.loc[i,'주요업무'].replace('\\\\t','').replace('•','').split('\\\\n')))        \n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            data.loc[i,'자격요건']='\\\\n'.join(strip_(data.loc[i,'자격요건'].replace('\\\\t','').replace('•','').split('\\\\n')))        \n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            data.loc[i,'우대사항']='\\\\n'.join(strip_(data.loc[i,'우대사항'].replace('\\\\t','').replace('•','').split('\\\\n')))        \n",
    "        except:\n",
    "            pass\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "def extract2to1(data):\n",
    "    for i in tqdm(range(len(data))):\n",
    "        print(i,'시작')\n",
    "        temp=list(data['유사직무'][i].split('\\\",\\\"'))\n",
    "        if len(temp)%2 == 1 and ('Software Engineer' in temp):\n",
    "            temp.remove('Software Engineer')\n",
    "        if len(temp)%2 == 1 and ('Performance Marketing Manager' in temp):\n",
    "            temp.remove('Performance Marketing Manager')\n",
    "        if len(temp)%2 == 1 and ('Administrative Assistant' in temp):\n",
    "            temp.remove('Administrative Assistant')    \n",
    "        temp = temp[1::2]\n",
    "        x=0\n",
    "        while x<len(temp):\n",
    "            if x+1 == len(temp):\n",
    "                temp[x] = str('\\\"'+temp[x])\n",
    "            else:\n",
    "                temp[x] = str('\\\"'+temp[x]+'\\\"')\n",
    "            x+=1\n",
    "\n",
    "        data.loc[i,'유사직무'] = ',  '.join(temp)\n",
    "        print(temp)\n",
    "        print(i,'끝')\n",
    "        \n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def counting_job(data):\n",
    "    a=list(data['유사직무'])\n",
    "    duplicated=[]\n",
    "    for i in tqdm(range(len(data))):\n",
    "        duplicated.extend(strip_(data['유사직무'][i].split(',  ')))\n",
    "    print('기존 유사직무 총 개수(중복포함) :',len(duplicated))\n",
    "    not_duplicated=set(duplicated)\n",
    "    print('기존 유사직무 개수(중복제거) :',len(not_duplicated))\n",
    "    not_duplicated = list(not_duplicated)\n",
    "    \n",
    "    return duplicated, not_duplicated\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def counting_data_per_job(data):    \n",
    "    sim_job={}\n",
    "    for i in range(len(not_duplicated)):\n",
    "        sim_job[not_duplicated[i]]=duplicated.count(not_duplicated[i])\n",
    "    dict_= sorted(sim_job.items(),key=operator.itemgetter(1), reverse=True)\n",
    "    return dict_\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "def rearrange(data):\n",
    "    new_data = pd.DataFrame(columns = ['직무','출연횟수','주요업무','자격요건','우대사항'])\n",
    "   \n",
    "    for i in tqdm(range(len(not_duplicated))):\n",
    "        temp1=[]\n",
    "        temp2=[]\n",
    "        temp3=[]\n",
    "        count = 0\n",
    "        for j in range(len(data)):\n",
    "            if not_duplicated[i] in data['유사직무'][j]:\n",
    "                count +=1\n",
    "                temp1.extend(str(data['주요업무'][j]).split('\\\\n'))\n",
    "                temp2.extend(str(data['자격요건'][j]).split('\\\\n'))\n",
    "                temp3.extend(str(data['우대사항'][j]).split('\\\\n'))\n",
    "\n",
    "        new_data=new_data.append({'직무' : not_duplicated[i],'출연횟수':count, '주요업무' : temp1, '자격요건' : temp2, '우대사항' : temp3} , ignore_index=True)\n",
    "\n",
    "    new_data=new_data.sort_values(by=['출연횟수','직무'],ascending = False)  \n",
    "    return new_data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def merge(kor,eng,ans):\n",
    "    index_eng = 0\n",
    "    index_kor = 0\n",
    "    answer=[]        \n",
    "\n",
    "    if len(eng) == 0:\n",
    "        answer = kor\n",
    "\n",
    "    else:\n",
    "        while True:\n",
    "            a = kor[index_kor]\n",
    "            b = eng[index_eng]\n",
    "            \n",
    "            if ans.find(a) < ans.find(b):\n",
    "                answer.append(a)\n",
    "                ans = ans[ans.find(a)+len(a):]\n",
    "                index_kor += 1\n",
    "                \n",
    "            else:\n",
    "                answer.append(b)\n",
    "                ans = ans[ans.find(b)+len(b):]\n",
    "                index_eng += 1\n",
    "                \n",
    "            if index_eng == len(eng) or index_kor == len(kor):\n",
    "                \n",
    "                if index_kor != len(kor):\n",
    "                \n",
    "                    while index_kor != len(kor):                    \n",
    "                        answer.append(kor[index_kor])\n",
    "                        index_kor += 1\n",
    "\n",
    "                else:\n",
    "                    while index_eng != len(eng):\n",
    "                        answer.append(eng[index_eng])\n",
    "                        index_eng +=1\n",
    "                break\n",
    "\n",
    "    return ' '.join(answer)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def nominalization(data):\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        if str(data['직무'][i])[0] == '\\\"':\n",
    "            data.loc[i,'직무'] = str(data['직무'][i])[1:]\n",
    "        if str(data['직무'][i])[-1] == '\\\"':\n",
    "            data.loc[i,'직무'] = str(data['직무'][i])[:-1]\n",
    "    \n",
    "    \n",
    "    data = data.drop(data.index[340],axis=0)\n",
    "    data = data.reset_index(drop=True)\n",
    "    \n",
    "    data = data.drop(data.index[349],axis=0)\n",
    "    data = data.reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    hangul = re.compile('[^ㄱ-ㅣ가-힣]+')\n",
    "    english = re.compile('[^a-zA-Z]+')\n",
    "\n",
    "    for i in tqdm(range(len(data))): \n",
    "        kor = Okt.nouns(hangul.sub(' ', str(data['주요업무'][i])))\n",
    "        eng = english.sub(' ', str(data['주요업무'][i])).lower().split()\n",
    "        ans =str(data['주요업무'][i]).lower()\n",
    "        data.loc[i,'주요업무'] = merge(kor,eng,ans)\n",
    "        \n",
    "\n",
    "        kor = Okt.nouns(hangul.sub(' ', str(data['자격요건'][i])))\n",
    "        eng = english.sub(' ', str(data['자격요건'][i])).lower().split()\n",
    "        ans =str(data['자격요건'][i]).lower()\n",
    "        data.loc[i,'자격요건'] = merge(kor,eng,ans)\n",
    "        \n",
    "\n",
    "        kor = Okt.nouns(hangul.sub(' ', str(data['우대사항'][i])))\n",
    "        eng = english.sub(' ', str(data['우대사항'][i])).lower().split()\n",
    "        ans =str(data['우대사항'][i]).lower()\n",
    "        data.loc[i,'우대사항'] = merge(kor,eng,ans)\n",
    "        \n",
    "        \n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def about_carrer(data):\n",
    "    for i in range(len(data)):\n",
    "        if str(data['직무'][i])[0] == '\\\"':\n",
    "            data.loc[i,'직무'] = str(data['직무'][i])[1:]\n",
    "        if str(data['직무'][i])[-1] == '\\\"':\n",
    "            data.loc[i,'직무'] = str(data['직무'][i])[:-1]\n",
    "\n",
    "    data = data.drop(data.index[340],axis=0)\n",
    "    data = data.reset_index(drop=True)\n",
    "    data = data.drop(data.index[349],axis=0)\n",
    "    data = data.reset_index(drop=True)\n",
    "\n",
    "    data=data.sort_values(by=['출연횟수','직무'],ascending = False)\n",
    "    data = data.reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    career = []\n",
    "    career_count=[]\n",
    "    mean = []\n",
    "    for i in range(len(data)):    \n",
    "        temp = []\n",
    "        text = ' '.join(data['자격요건'][i])\n",
    "        num = re.findall('\\d+',text)\n",
    "        for j in num:\n",
    "            try:\n",
    "                if text[text.find(j) + len(str(j))] == '년' and text[text.find(j) + len(str(j)):text.find(j) + len(str(j))+2] != '년제' and int(j)<30: \n",
    "                    text = text[text.find(j) + len(str(j))+1:]\n",
    "                    temp.append(j)\n",
    "            except:\n",
    "                pass\n",
    "        if len(temp) == 0:\n",
    "            career.append('nan')\n",
    "            career_count.append(int(0))\n",
    "        else:\n",
    "            career.append(round(sum(map(int,temp))/len(temp),2))\n",
    "            career_count.append(len(temp))\n",
    "\n",
    "\n",
    "    career_count_ = []\n",
    "    for i in range(len(career_count)):\n",
    "        if int(career_count[i]) / int(data['출연횟수'][i]) * 100 > 100:\n",
    "            career_count_.append('100%') \n",
    "        else:\n",
    "            career_count_.append(str(int(career_count[i]) / int(data['출연횟수'][i]) * 100) +'%')\n",
    "    return career,career_count_\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def tf(t, d):\n",
    "    return d.count(t)\n",
    "\n",
    "\n",
    "def idf(t,docs):\n",
    "    df = 0\n",
    "    N = len(docs)\n",
    "    for doc in docs:\n",
    "        df += t in doc\n",
    "    return log(N/(df + 1))\n",
    "\n",
    "\n",
    "def tfidf(t, d,docs):\n",
    "    return tf(t,d)* idf(t,docs)\n",
    "\n",
    "\n",
    "\n",
    "def dtm(): \n",
    "    result = []\n",
    "    for j in range(len(vocab)):\n",
    "        t = vocab[j]\n",
    "        result.append(idf(t))\n",
    "\n",
    "    idf_ = pd.DataFrame(result, index = vocab, columns = [\"IDF\"])\n",
    "    return idf_\n",
    "\n",
    "\n",
    "\n",
    "def final(docs):\n",
    "    N = len(docs)\n",
    "    vocab = list(set(w for doc in docs for w in doc.split())) \n",
    "    vocab.sort()\n",
    "\n",
    "    result = []\n",
    "    for i in range(N):\n",
    "        result.append([])\n",
    "        d = docs[i]\n",
    "        for j in range(len(vocab)):\n",
    "            t = vocab[j]\n",
    "\n",
    "            result[-1].append(tfidf(t,d,docs))\n",
    "\n",
    "    tfidf_ = pd.DataFrame(result, columns = vocab)\n",
    "    return tfidf_    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def final(docs):\n",
    "    N = len(docs)\n",
    "    vocab = list(set(w for doc in docs for w in doc.split())) \n",
    "    vocab.sort()\n",
    "\n",
    "    result = []\n",
    "    for i in range(N):\n",
    "        result.append([])\n",
    "        d = docs[i]\n",
    "        for j in range(len(vocab)):\n",
    "            t = vocab[j]\n",
    "\n",
    "            result[-1].append(tfidf(t,d,docs))\n",
    "\n",
    "    tfidf_ = pd.DataFrame(result, columns = vocab)\n",
    "    return tfidf_\n",
    "\n",
    "\n",
    "\n",
    "def extract_keyword_tfidf(data):\n",
    "    temp1=list(data['주요업무'])\n",
    "    temp2=list(data['자격요건'])\n",
    "    temp3=list(data['우대사항'])\n",
    "    \n",
    "    x= final(temp1)\n",
    "    x_=[]\n",
    "    for i in tqdm(range(len(temp1))):\n",
    "        if len(sorted(x.loc[i].items(),key = lambda item:item[1],reverse = True)) > 100:\n",
    "            temp= dict(sorted(x.loc[i].items(),key = lambda item:item[1],reverse = True)[:100]).keys()\n",
    "        else:\n",
    "            temp= dict(sorted(x.loc[i].items(),key = lambda item:item[1],reverse = True)).keys()\n",
    "        x_.append(str(list(temp))[1:-1])\n",
    "    data['TF_IDF기준 주요업무 상위100keywords'] = x_\n",
    "    \n",
    "    \n",
    "    y= final(temp2)\n",
    "    y_=[]\n",
    "    for i in tqdm(range(len(temp2))):\n",
    "        if len(sorted(y.loc[i].items(),key = lambda item:item[1],reverse = True)) > 100:\n",
    "            temp= dict(sorted(y.loc[i].items(),key = lambda item:item[1],reverse = True)[:100]).keys()\n",
    "        else:\n",
    "            temp= dict(sorted(y.loc[i].items(),key = lambda item:item[1],reverse = True)).keys()\n",
    "        y_.append(str(list(temp))[1:-1])\n",
    "    data['TF_IDF기준 자격요건 상위100keywords'] = y_\n",
    "    \n",
    "    \n",
    "    \n",
    "    z= final(temp3)\n",
    "    z_=[]\n",
    "    for i in tqdm(range(len(temp3))):\n",
    "        if len(sorted(z.loc[i].items(),key = lambda item:item[1],reverse = True)) > 100:\n",
    "            temp= dict(sorted(z.loc[i].items(),key = lambda item:item[1],reverse = True)[:100]).keys()\n",
    "        else:\n",
    "            temp= dict(sorted(z.loc[i].items(),key = lambda item:item[1],reverse = True)).keys()\n",
    "        z_.append(str(list(temp))[1:-1])\n",
    "    data['TF_IDF기준 우대사항 상위100keywords'] = z_\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def Doc2vec_embeddnig(data):\n",
    "    temp = data['주요업무'] + data['자격요건'] + data['우대사항']\n",
    "    tagged_text = [TaggedDocument(words=word_tokenize(d.lower()), tags=[str(i)]) for i,d in enumerate(temp)]\n",
    "    \n",
    "    \n",
    "    max_epochs = 100\n",
    "    vec_size = 16\n",
    "    alpha = 0.025\n",
    "\n",
    "    model = Doc2Vec(size=vec_size,\n",
    "                    alpha=alpha, \n",
    "                    min_alpha=0.00025,\n",
    "                    min_count=5,\n",
    "                    dm =1)\n",
    "\n",
    "    model.build_vocab(tagged_text)\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        print('iteration {0}'.format(epoch))\n",
    "        model.train(tagged_text,\n",
    "                    total_examples=model.corpus_count,\n",
    "                    epochs=model.iter)\n",
    "        # decrease the learning rate\n",
    "        model.alpha -= 0.0002\n",
    "        # fix the learning rate, no decay\n",
    "        model.min_alpha = model.alpha\n",
    "\n",
    "    model.save(\"d2v.model\")\n",
    "    print(\"Model Saved\")\n",
    "\n",
    "\n",
    "\n",
    "    model= Doc2Vec.load(\"d2v.model\")\n",
    "\n",
    "    vector_lis = []\n",
    "    for i in range(len(temp)):\n",
    "        v=model.infer_vector(word_tokenize(temp[i].lower()))\n",
    "        vector_lis.append(v)\n",
    "        \n",
    "    return vector_lis\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def visualization(data,list_):\n",
    "    text_standard = StandardScaler().fit_transform(vector_lis)\n",
    "    pca = PCA(n_components=2)\n",
    "    principalComponents = pca.fit_transform(text_standard)\n",
    "    \n",
    "    df = pd.DataFrame(data = principalComponents, columns = ['principal_component_1', 'principal_component_2'],index=data['직무'])\n",
    "    \n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(50, 50))\n",
    "    ax=sns.scatterplot(x='principal_component_1',y='principal_component_2',data=df) \n",
    "    plt.title('시각화')\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        ax.text(float(df['principal_component_1'][i]) - 0.5, float(df['principal_component_2'][i]) + 0.05, df.index[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0      0\n",
      "주소번호            0\n",
      "직무             63\n",
      "유사직무          356\n",
      "주요업무           31\n",
      "자격요건           46\n",
      "우대사항          279\n",
      "dtype: int64\n",
      "기존 데이터 개수는  50926\n",
      "중복제거 데이터 개수는  50926\n",
      "직무,유사직무 결측값제거 데이터 개수 50567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-6aaab0e6dc84>:21: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for i in tqdm_notebook(range(len(data))):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "478e51b0dc4646beb0e6108906fd8439",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=50567.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-6aaab0e6dc84>:33: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for i in tqdm_notebook(range(len(data))):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abd7a0e926384a85974bcaa140715dc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=50567.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "완료된 데이터 개수 50500\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00a6bc666ab24e84891ddf60fb7ce489",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=49106.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "checking_null(data)\n",
    "data = del_null(data)\n",
    "data = del_chinese_japanese(data)\n",
    "data = del_error(data)\n",
    "data = extract2to1(data)\n",
    "duplicated, not_duplicated = counting_job(data)\n",
    "print(duplicated)\n",
    "print(not_duplicated)\n",
    "sub_explain = counting_data_per_job(data)\n",
    "print(sub_explain)\n",
    "data = rearrange(data)\n",
    "data_sub = data\n",
    "\n",
    "career, career_count = about_carrer(data_sub)\n",
    "data = nominalization(data)\n",
    "\n",
    "data['요구된 평균경력'] = career\n",
    "data['경력 요구 비율'] = career_count\n",
    "\n",
    "data = data[data['출연횟수']>9]\n",
    "\n",
    "data = extract_keyword_tfidf(data)\n",
    "\n",
    "vector_lis = Doc2vec_embeddnig(data)\n",
    "visualization(data,vector_lis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
