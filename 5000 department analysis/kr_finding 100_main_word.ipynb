{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version 1. 전부 다같이 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import operator\n",
    "import pandas as pd\n",
    "import re\n",
    "from konlpy.tag import Okt\n",
    "okt=Okt()\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "\n",
    "#데이터 알맞은 형태로 전처리\n",
    "def preprocess(documents):      \n",
    "# 저장된 데이터에서 필요한건 '학교명', '학과명', '학과소개글', '배우는과목소개글'\n",
    "# 따라서 얘네 4명만 살리고 학교명과 학과명은 하나로 합친 데이터정제 코드 \n",
    "    documents = documents[['name','univname','text_intr','text_lect']]\n",
    "    documents['name']=documents['univname']+' '+documents['name']\n",
    "    documents = documents.drop(['univname'],axis=1)\n",
    "    documents['text_intr']=documents['text_intr']+' '+documents['text_lect']\n",
    "    documents = documents.drop(['text_lect'],axis=1)\n",
    "    documents = documents.dropna(axis=0)\n",
    "    documents=documents.reset_index()\n",
    "    return documents\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 한글과 띄어쓰기를 제외한 모든 부분을 제거, 명사만 남김\n",
    "def trans_hangul(documents):\n",
    "    text_list = list(documents['text_intr'])\n",
    "    hangul = re.compile('[^ ㄱ-ㅣ가-힣]+')\n",
    "    for i in range(len(text_list)):   \n",
    "        text_list[i] = hangul.sub('', text_list[i])\n",
    "        text_list[i]=(' '.join(okt.nouns(text_list[i])))\n",
    "        \n",
    "    return text_list\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def make_top100(documents,n):\n",
    "\n",
    "# text_list_vec는 documents를 tfidf 벡터화한 벡터값(학습된 값)    \n",
    "    text_list_vec = TfidfVectorizer().fit(documents)\n",
    "\n",
    "# word_index는 각 단어의 고유 인덱스 값    \n",
    "    word_index=text_list_vec.vocabulary_\n",
    "    \n",
    "\n",
    "    text_list_vec=text_list_vec.transform(documents).toarray()\n",
    "    word_index = {v: k for k, v in word_index.items()}\n",
    "    word_index= sorted(word_index.items(), key=operator.itemgetter(0))\n",
    "    \n",
    "# 이부분이 제일 중요!!!! 여기서 설정하는 값이 데이터의 n번째 학과의 top100을 도출시켜줌    \n",
    "    index_of_major = n\n",
    "\n",
    "    result={}\n",
    "    for i in range(len(text_list_vec[index_of_major])):\n",
    "        if text_list_vec[index_of_major][i] != 0:\n",
    "            result[word_index[i][1]] =  text_list_vec[index_of_major][i]\n",
    "    result= sorted(result.items(), key=operator.itemgetter(1),reverse=True)\n",
    "    top100={}\n",
    "    for i in range(100):\n",
    "        top100[result[i][0]] = result[i][1]\n",
    "        \n",
    "    return top100\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'중국어': 0.6436017425317165,\n",
       " '중국': 0.5473780387607348,\n",
       " '문학': 0.11510215632399859,\n",
       " '문화': 0.11254997811566504,\n",
       " '중어': 0.11039871458716347,\n",
       " '중국문학': 0.10128580394003896,\n",
       " '현대문학': 0.09594971453370334,\n",
       " '이해': 0.09364667950554247,\n",
       " '한자': 0.08440483661669915,\n",
       " '한중': 0.08440483661669915,\n",
       " '편성': 0.08135419466165604,\n",
       " '능력': 0.08105922984335887,\n",
       " '중국인': 0.0790167424490227,\n",
       " '대한': 0.07866321078465567,\n",
       " '언어능력': 0.07483741192229264,\n",
       " '어문학': 0.07142265024308563,\n",
       " '작품': 0.07108893107420089,\n",
       " '문법': 0.06714292452233252,\n",
       " '독해력': 0.06603455607540919,\n",
       " '고급': 0.06411229332509145,\n",
       " '문장': 0.06366284364215481,\n",
       " '현대': 0.05498079942681256,\n",
       " '교육': 0.05350161373919628,\n",
       " '구사': 0.05282764486032735,\n",
       " '관련': 0.05223019563784956,\n",
       " '작가': 0.051916910795917995,\n",
       " '장르': 0.051916910795917995,\n",
       " '회화': 0.051916910795917995,\n",
       " '문학사': 0.05106284642971883,\n",
       " '중국학': 0.05064290197001948,\n",
       " '전문가': 0.049828732181505665,\n",
       " '언어학': 0.049484180438943294,\n",
       " '동시': 0.04658248621112291,\n",
       " '사회': 0.04585852606216824,\n",
       " '지식': 0.04540217284134643,\n",
       " '특색': 0.044902447153375574,\n",
       " '무역': 0.04444265920608253,\n",
       " '학습': 0.04331805553056822,\n",
       " '교류': 0.04325227945759795,\n",
       " '대표': 0.042514051879165286,\n",
       " '통해': 0.04203698222365422,\n",
       " '강독': 0.03986698281209958,\n",
       " '역점': 0.039620733645245515,\n",
       " '강좌': 0.039444488993969726,\n",
       " '교양': 0.03909843134005248,\n",
       " '수준': 0.03897130934669409,\n",
       " '지향': 0.038391807107259576,\n",
       " '양성': 0.03764148640128769,\n",
       " '어학': 0.037113135329207465,\n",
       " '중국어학': 0.03679957152905449,\n",
       " '독해': 0.036042077505797326,\n",
       " '소설': 0.036042077505797326,\n",
       " '학년': 0.03542837656597107,\n",
       " '소양': 0.034718056973301145,\n",
       " '어휘': 0.03416479026661213,\n",
       " '분석': 0.03405162963100982,\n",
       " '교과목': 0.03395611271461801,\n",
       " '시대': 0.0337644020962989,\n",
       " '어법': 0.033761934646679655,\n",
       " '청대': 0.033761934646679655,\n",
       " '향후': 0.03353112041442491,\n",
       " '배양': 0.033459099023366835,\n",
       " '작문': 0.033331994404561895,\n",
       " '특징': 0.03215713660447573,\n",
       " '연습': 0.032089905566183616,\n",
       " '학문': 0.031746401229266294,\n",
       " '디자인': 0.03147601772011752,\n",
       " '스톤': 0.03147601772011752,\n",
       " '문자': 0.031150146477550805,\n",
       " '인문': 0.030507822998121013,\n",
       " '전공': 0.030482490530745244,\n",
       " '스토리텔링': 0.02993496476891705,\n",
       " '구문': 0.02856906009723425,\n",
       " '사유': 0.02856906009723425,\n",
       " '시가': 0.02856906009723425,\n",
       " '언어': 0.027981636342442048,\n",
       " '중요': 0.027753234486077926,\n",
       " '산문': 0.027414204152486667,\n",
       " '청취': 0.027414204152486667,\n",
       " '한문': 0.027414204152486667,\n",
       " '분야': 0.02729146664808419,\n",
       " '훈련': 0.02728460514328147,\n",
       " '실무': 0.026797613837063108,\n",
       " '기초': 0.02675080686959814,\n",
       " '전문': 0.026662998191242602,\n",
       " '파악': 0.026511664223164755,\n",
       " '마련': 0.025951367674558766,\n",
       " '통상': 0.025531423214859416,\n",
       " '당시': 0.024742090219471647,\n",
       " '집중': 0.024042109996909294,\n",
       " '공지': 0.023376185547788843,\n",
       " '증진': 0.02241061241940391,\n",
       " '듣기': 0.022221329603041264,\n",
       " '발음': 0.022221329603041264,\n",
       " '미래': 0.022146103191780297,\n",
       " '실용': 0.022110925284906574,\n",
       " '고대': 0.021704453337096814,\n",
       " '대해': 0.021337621938480548,\n",
       " '위해': 0.021337621938480548,\n",
       " '요구': 0.021209331378531805}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#####################main############################\n",
    "# 현 코드에는 연습용데이터불러오는 코드임.  \n",
    "#실무에선 실제 저장된 학과관련 데이터와 연결하는 코드를 써야함.\n",
    "documents=pd.read_excel('example.xlsx')\n",
    "\n",
    "\n",
    "#########이부분은 데이터를 훈련시켜서 각 학과마다 tdidf 돌리는 부분, 시간이 가장 오래걸릴 코드#########\n",
    "x=preprocess(documents)\n",
    "x=trans_hangul(x)\n",
    "\n",
    "\n",
    "\n",
    "###훈련 다된 데이터에서 원하는 것만 뽑아와서 순서매기고 출력###\n",
    "#받은 데이터에서 보고싶은 학과의 index입력(순서)\n",
    "wanted_index = 4   \n",
    "make_top100(x,wanted_index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version 2. 한 학과선택, 램덤한 개수의 학과와 비교해 tfidf학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time : 0.0\n",
      "time : 1.4940106868743896\n",
      "time : 1.5628273487091064\n",
      "국민대학교 공업디자인학과\n",
      "time : 1.7353806495666504\n",
      "time : 13.881948232650757\n",
      "{'디자인': 0.7322765380540905, '제품': 0.2746818834777818, '조형': 0.22674575760616156, '환경': 0.1506627365937207, '공업': 0.12086002873022397, '산업': 0.11791843944890441, '학습': 0.11134492740153834, '제품디자인': 0.09796337184905783, '기능': 0.09498920846920518, '가능성': 0.0898870021987487, '형태': 0.08649963191766738, '사용자': 0.08502965910231058, '개발': 0.0799117775467422, '해결': 0.07972116051272439, '정보기기': 0.07598882117083529, '기획': 0.07485568819120879, '능력': 0.07478042046942987, '디자이너': 0.07382696211378532, '제안': 0.07382696211378532, '방법': 0.07112125073682193, '메카트로닉스': 0.07085804925192549, '재료': 0.07065325238389385, '관계': 0.06777847886466301, '바탕': 0.06565038529552794, '색채': 0.06530891456603856, '시스템': 0.0638156429399507, '표현': 0.062908823212849, '기법': 0.06093501797075269, '이해': 0.05861966622757901, '이론': 0.05687916556921176, '입체': 0.05462900796124181, '프로세스': 0.053768757975626615, '인간': 0.053408302054897536, '컨텐츠': 0.05281422481601797, '로봇': 0.05119084597438464, '구조': 0.05028840448369686, '디지털': 0.049698984902166704, '측면': 0.0491926045546468, '스케치': 0.048981685924528916, '미래': 0.047855915820421986, '중심': 0.047685298838181775, '특성': 0.047685298838181775, '인간공학': 0.04640306443438603, '요소': 0.044746549147186766, '인터페이스': 0.044296177268271196, '습득': 0.04423032619660226, '전개': 0.04213431821122123, '공간': 0.0413012586681081, '요구': 0.04005622654117315, '종합': 0.04005622654117315, '테크닉': 0.039610668612013476, '공공시설': 0.037994410585417644, '디자인학': 0.037994410585417644, '상표권': 0.037994410585417644, '소유권': 0.037994410585417644, '실용신안': 0.037994410585417644, '의장권': 0.037994410585417644, '특허권': 0.037994410585417644, '상품': 0.03729174088717867, '발전': 0.036561010782451615, '모색': 0.036468470584408066, '공정': 0.03628624731467364, '경험': 0.03502031202445916, '가상현실': 0.0348707381479125, '생산품': 0.0348707381479125, '창업': 0.034504899597557745, '분석': 0.03419713343305183, '크기': 0.03265445728301928, '활용': 0.032482789756361735, '조건': 0.03226125478537597, '기기': 0.03160073865841592, '가상': 0.030935376289590685, '스케': 0.030935376289590685, '이슈': 0.030383204527190934, '개념': 0.03013254731874414, '제반': 0.029819390941300025, '발상': 0.02953078484551413, '판매': 0.02953078484551413, '사회': 0.029017407191977318, '고려': 0.028768131422948616, '마케팅': 0.028768131422948616, '파악': 0.028716726982513353, '구체화': 0.028343219700770195, '인터': 0.028343219700770195, '편집': 0.028343219700770195, '담당': 0.02827631736107609, '시각': 0.027804583037048056, '소비': 0.027314503980620904, '대상': 0.027021849876638058, '사용': 0.026704151027448768, '별로': 0.026494969643960194, '인문': 0.026407112408008984, '여러': 0.026392870777934008, '생산': 0.026089458344844035, '시뮬레이션': 0.02559542298719232, '테이': 0.02559542298719232, '프레': 0.02559542298719232, '제도': 0.025318780409153717, '제작': 0.02495189606373626, '이미지': 0.024861160591452443}\n",
      "time : 14.016587972640991\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import operator\n",
    "import pandas as pd\n",
    "import re\n",
    "from konlpy.tag import Okt\n",
    "okt=Okt()\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "import time\n",
    "start = time.time()  # 시작 시간 저장\n",
    " \n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#데이터 알맞은 형태로 전처리\n",
    "# 저장된 데이터에서 필요한건 '학교명', '학과명', '학과소개글', '배우는과목소개글'\n",
    "# 따라서 얘네 4명만 살리고 학교명과 학과명은 하나로 합친 데이터정제 코드\n",
    "# 결론적적으로 데이터가 들어오면 '학교+학과' , '학과관련text'으로 return\n",
    "def preprocess(documents):      \n",
    "    documents = documents[['name','univname','text_intr','text_lect']]\n",
    "    documents['name']=documents['univname']+' '+documents['name']\n",
    "    documents = documents.drop(['univname'],axis=1)\n",
    "    documents['text_intr']=documents['text_intr']+' '+documents['text_lect']\n",
    "    documents = documents.drop(['text_lect'],axis=1)\n",
    "    documents = documents.dropna(axis=0)\n",
    "    documents=documents.reset_index(drop=True)\n",
    "    return documents\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 선택한 학과와 그 외 학과를 랜덤으로 50개뽑아서 return\n",
    "# n에는 원하는 학과의 인덱스를 입력\n",
    "def random_choice(documents,n):\n",
    "    df = pd.DataFrame( columns=['name', 'text_intr'])\n",
    "    df=df.append(documents.loc[[n],:])\n",
    "         \n",
    "    x=[i for i in range(0,len(documents))]\n",
    "    random.shuffle(x)\n",
    "    x=x[:100]\n",
    "    if n in x:\n",
    "        x.remove(n)\n",
    "    for i in x:\n",
    "        df=df.append(documents.loc[[i],:])\n",
    "        \n",
    "    return df\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 한글과 띄어쓰기를 제외한 모든 부분을 제거, 명사만 남김\n",
    "def trans_hangul(documents):\n",
    "    text_list = list(documents['text_intr'])\n",
    "    hangul = re.compile('[^ ㄱ-ㅣ가-힣]+')\n",
    "    for i in range(len(text_list)):   \n",
    "        text_list[i] = hangul.sub('', text_list[i])\n",
    "        text_list[i]=(' '.join(okt.nouns(text_list[i])))\n",
    "        \n",
    "    return text_list\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 방대한 자료를 벡터화하는 함수(tfidf 훈련시키는 함수)\n",
    "def make_top100(documents):\n",
    "    global text_list_vec,word_index\n",
    "    \n",
    "# text_list_vec는 documents를 tfidf 벡터화한 벡터값(학습된 값)    \n",
    "    text_list_vec = TfidfVectorizer().fit(documents)\n",
    "# word_index는 각 단어의 고유 인덱스 값    \n",
    "    word_index=text_list_vec.vocabulary_\n",
    "\n",
    "    text_list_vec=text_list_vec.transform(documents).toarray()\n",
    "    word_index = {v: k for k, v in word_index.items()}\n",
    "    word_index = sorted(word_index.items(), key=operator.itemgetter(0))\n",
    "  \n",
    "    \n",
    "# 학습된 tfidf를 바탕으로 중요도 높은 top100개를 도출\n",
    "\n",
    "    result={}\n",
    "    for i in range(len(text_list_vec[0])):\n",
    "        if text_list_vec[0][i] != 0:\n",
    "            result[word_index[i][1]] =  text_list_vec[0][i]\n",
    "    result= sorted(result.items(), key=operator.itemgetter(1),reverse=True)\n",
    "    top100={}\n",
    "    for i in range(100):\n",
    "        top100[result[i][0]] = result[i][1]\n",
    "        \n",
    "    return top100\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#####################main############################\n",
    "# 현 코드에는 연습용데이터불러오는 코드임.  \n",
    "#실무에선 실제 저장된 학과관련 데이터와 연결하는 코드를 써야함.\n",
    "print(\"time :\", time.time() - start)  # 현재시각 - 시작시간 = 실행 시간\n",
    "\n",
    "documents=pd.read_excel('majors_textSet_복구.xlsx')\n",
    "\n",
    "\n",
    "\n",
    "# 알고 싶은 학과의 index를 wanted_index의 값으로 입력\n",
    "wanted_index = 100\n",
    "\n",
    "\n",
    "\n",
    "# 정리\n",
    "# 5000개 기존데이터 입력 -> 데이터 중 필요한 부분만 남기도록 전처리 -> 원하는 학과(index로 선택)와 그 외 50개만 뽑음\n",
    "# -> 51개 데이터 에서 한글과 띄어쓰기만 남김, 그리고 단어만 남김(조사 형용사 전부 삭제) \n",
    "# -> 총 51개를 tfidf학습시킴(서로 비교하면서 각 단어에 점수가 메겨짐)\n",
    "# -> 원하는 학과 데이터 중에서 단어의 점수를 내림차순으로 정렬한 뒤 top100개만 뽑음\n",
    "\n",
    "\n",
    "\n",
    "# 실제 실행 코드\n",
    "print(\"time :\", time.time() - start)  # 현재시각 - 시작시간 = 실행 시간\n",
    "\n",
    "documents = preprocess(documents)\n",
    "\n",
    "print(\"time :\", time.time() - start)  # 현재시각 - 시작시간 = 실행 시간\n",
    "\n",
    "print(documents['name'][wanted_index])\n",
    "documents = random_choice(documents,wanted_index)\n",
    "\n",
    "print(\"time :\", time.time() - start)  # 현재시각 - 시작시간 = 실행 시간\n",
    "\n",
    "documents =trans_hangul(documents)\n",
    "\n",
    "print(\"time :\", time.time() - start)  # 현재시각 - 시작시간 = 실행 시간\n",
    "\n",
    "\n",
    "top100 = make_top100(documents)\n",
    "print(top100)\n",
    "\n",
    "\n",
    " \n",
    "print(\"time :\", time.time() - start)  # 현재시각 - 시작시간 = 실행 시간\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
